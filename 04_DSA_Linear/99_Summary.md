---
title: DSA Linear - Summary
tags: [dsa, summary, sorting, searching, data-structures]
---

# DSA Linear - Zusammenfassung

## ğŸ“‹ Ãœberblick

Dieser Kurs behandelt die fundamentalen Konzepte der Datenstrukturen und Algorithmen. Beginnend mit Big O Notation und Arrays, durchlaufen Sie 8 verschiedene Sortieralgorithmen (vom einfachen Bubble Sort bis zum effizienten Merge Sort), lernen 2 Suchalgorithmen (Linear und Binary Search) und verstehen zwei grundlegende Datenstrukturen (Stacks und Queues). Das Ziel ist es, Ihnen die Werkzeuge zu geben, um effiziente LÃ¶sungen zu schreiben und technische Interviews zu bestehen.

---

## ğŸ“Š KomplexitÃ¤ts-Ãœbersicht

### Sortieralgorithmen

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    SORTING ALGORITHMS                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Algorithm         â•‘   Best    â•‘ Average   â•‘  Worst  â•‘  Space    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Bubble Sort       â•‘   O(n)    â•‘   O(nÂ²)   â•‘  O(nÂ²)  â•‘  O(1)     â•‘
â•‘ Selection Sort    â•‘   O(nÂ²)   â•‘   O(nÂ²)   â•‘  O(nÂ²)  â•‘  O(1)     â•‘
â•‘ Insertion Sort    â•‘   O(n)    â•‘   O(nÂ²)   â•‘  O(nÂ²)  â•‘  O(1)     â•‘
â•‘ Quick Sort        â•‘ O(n log n)â•‘ O(n log n)â•‘  O(nÂ²)  â•‘ O(log n)  â•‘
â•‘ Merge Sort        â•‘ O(n log n)â•‘ O(n log n)â•‘O(n log n)â•‘  O(n)    â•‘
â•‘ Heap Sort         â•‘ O(n log n)â•‘ O(n log n)â•‘O(n log n)â•‘  O(1)    â•‘
â•‘ Counting Sort     â•‘  O(n+k)   â•‘  O(n+k)   â•‘ O(n+k)  â•‘  O(k)    â•‘
â•‘ Radix Sort        â•‘  O(d*n)   â•‘  O(d*n)   â•‘ O(d*n)  â•‘ O(n+k)   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Stable            â•‘  Ja âœ“     â•‘  Ja âœ“     â•‘  Nein âœ— â•‘  Ja âœ“     â•‘
â•‘ In-Place          â•‘  Ja âœ“     â•‘  Ja âœ“     â•‘  Ja âœ“   â•‘  Nein âœ—   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•
```

### Such- und Datenstruktur-Algorithmen

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         SEARCHING & DATA STRUCTURES                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Algorithm/Structure â•‘  Time   â•‘ Space   â•‘   Use Case         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Linear Search       â•‘  O(n)   â•‘  O(1)   â•‘ Unsorted Arrays    â•‘
â•‘ Binary Search       â•‘ O(log n)â•‘  O(1)   â•‘ Sorted Arrays      â•‘
â•‘ Stack (LIFO)        â•‘  O(1)*  â•‘  O(n)   â•‘ Undo/Redo          â•‘
â•‘ Queue (FIFO)        â•‘  O(1)*  â•‘  O(n)   â•‘ Task Scheduling    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ *push/pop/enqueue/dequeue - alle O(1) Operationen           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ“ Topic-Zusammenfassungen

### 01. Why Learn Data Structures and Algorithms?

DSA bildet die Grundlage fÃ¼r effizienten Code. WÃ¤hrend naive LÃ¶sungen fÃ¼r 1 Million Elemente bis zu 1 Million Operationen benÃ¶tigen, kÃ¶nnen optimierte Algorithmen dasselbe in etwa 20 Operationen erreichen. Das ist nicht nur fÃ¼r Interviews wichtig, sondern essentiell fÃ¼r echte Produktionsanwendungen wie Netflix-Empfehlungen, Google-Suche oder soziale Netzwerke.

### 02. Big O Notation

Big O Notation beschreibt, wie die Laufzeit mit der EingabegrÃ¶ÃŸe wÃ¤chst. Die wichtigsten KomplexitÃ¤tsklassen in aufsteigender Reihenfolge sind: O(1) < O(log n) < O(n) < O(n log n) < O(nÂ²) < O(2â¿). Man ignoriert Konstanten und niedrigere Terme, weshalb O(2n) = O(n) ist. Dies hilft uns, Algorithmen zu vergleichen unabhÃ¤ngig von Hardwaredetails.

### 03. Arrays

Arrays sind die Grundlage: Elemente in zusammenhÃ¤ngendem Speicher, direkter Zugriff durch Index in O(1). Allerdings kosten Insertionen und Deletionen in der Mitte O(n) wegen notwendiger Verschiebungen. Python-Lists sind dynamische Arrays, die bei Bedarf wachsen. Wichtige Operationen: append O(1), insert O(n), remove O(n).

### 04. Bubble Sort

Der einfachste Sortieralgorithmus: Vergleiche benachbarte Elemente und tausche sie, wenn sie in der falschen Reihenfolge sind. GrÃ¶ÃŸere Werte "blubbern" nach hinten. KomplexitÃ¤t: O(nÂ²) durchschnittlich und im worst-case, O(n) im best-case wenn bereits sortiert. Stabil und in-place, aber selten praktisch verwendet.

### 05. Selection Sort

Finde das Minimum in der unsortierten Portion und platziere es am Anfang. Wiederhole fÃ¼r die verbleibenden Elemente. KomplexitÃ¤t: O(nÂ²) in allen FÃ¤llen - keine Best-Case-Optimierung. Macht genau n-1 Swaps, was es vorteilhaft macht wenn Memory-Zugriffe teuer sind. Nicht stabil, aber einfach und O(1) Space.

### 06. Insertion Sort

Baue schrittweise einen sortierten Array auf, Ã¤hnlich wie Kartenspielen. Nimm jedes Element und fÃ¼ge es an der korrekten Position ein. KomplexitÃ¤t: O(n) best-case (bereits sortiert), O(nÂ²) worst-case. Adaptive Algorithmus - schnell bei fast-sortierten Daten. Stabil und online-fÃ¤hig. In der Praxis kombiniert mit Quick/Merge Sort fÃ¼r kleine Subarrays.

### 07. Quick Sort

Divide & Conquer mit Partitionierung: WÃ¤hle einen Pivot, teile Array in kleinere und grÃ¶ÃŸere Elemente. Sortiere rekursiv beide Seiten. DurchschnittskomplexitÃ¤t: O(n log n), worst-case: O(nÂ²) bei ungÃ¼nstigen Pivots. In-place mit O(log n) Stack Space. Nicht stabil, aber praktisch am schnellsten wegen guter Cache-LokalitÃ¤t.

### 08. Counting Sort

Nicht-vergleichender Algoritmus fÃ¼r Integers mit bekanntem Bereich: ZÃ¤hle Vorkommen jeden Werts, rekonstruiere dann sortiertes Array. KomplexitÃ¤t: O(n+k) wobei k der Wertebereich ist. Wenn k â‰¤ n, effektiv O(n) - linear! Space: O(k). Stabil bei korrekter Implementierung. Nicht geeignet fÃ¼r groÃŸe oder unbekannte Wertebereiche.

### 09. Radix Sort

Sortiere nach Ziffern von rechts nach links mit Counting Sort fÃ¼r jede Position. KomplexitÃ¤t: O(dÃ—(n+k)) wobei d die Anzahl der Ziffern ist. Bei Dezimalzahlen effektiv O(dÃ—n) - linear und oft schneller als O(n log n). Stabil und effizient fÃ¼r groÃŸe Integer-Arrays mit wenig Ziffern. Funktioniert auch fÃ¼r Strings.

### 10. Merge Sort

Klassischer Divide & Conquer: Teile Array in halbe, sortiere rekursiv, merge. Garantiert O(n log n) in allen FÃ¤llen. Space: O(n) fÃ¼r temporÃ¤re Arrays. Stabil und vorhersehbar, wichtig fÃ¼r Linked Lists und externe Sortierung. Nachteil: extra Memory und weniger cache-friendly als Quick Sort.

### 11. Linear Search

Der einfachste Suchalgorithmus: Checke sequenziell bis Element gefunden. KomplexitÃ¤t: O(1) best-case, O(n) average/worst-case. Funktioniert auf unsortierter und sortierter Array gleich gut. Keine Preprocessing nÃ¶tig. O(1) Space. Akzeptabel fÃ¼r kleine Arrays oder wenn nur einmal gesucht wird.

### 12. Binary Search

Das optimale Suchalgorithmus fÃ¼r sortierte Arrays: Halbiere Suchraum durch ÃœberprÃ¼fung der Mitte. KomplexitÃ¤t: O(log n) - selbst 1 Milliarde Elemente brauchen nur ~30 Vergleiche! Requirement: Array muss sortiert sein. Iterative Version bevorzugt wegen O(1) Space (vs. O(log n) rekursiv). Viele Varianten: first/last occurrence, insert position.

### 13. Stacks (LIFO)

Datenstruktur nach Last-In-First-Out Prinzip: push() und pop() beide O(1). Beispiele: Browser-Back, Undo/Redo, Funktionsaufrufe, Parentheses-Balancing. Python-Lists arbeiten wie Stacks. Nicht fÃ¼r random Access geeignet, aber essentiell fÃ¼r DFS und Backtracking. Einfach aber vielseitig.

### 14. Queues (FIFO)

Datenstruktur nach First-In-First-Out Prinzip: enqueue() hinten, dequeue() vorne, beide O(1). Verwende `collections.deque` fÃ¼r O(1) Operationen (nicht list.pop(0) das ist O(n)!). Anwendungen: Task-Scheduling, BFS, Druckerwarteschlangen. Varianten: Circular Queue (fixed-size), Priority Queue (Heap-basiert).

---

## âœ… Selbsttest-Checkliste

### Big O & KomplexitÃ¤t
- [ ] Ich kann Big O Notation erklÃ¤ren (Best, Average, Worst Case)
- [ ] Ich verstehe den Unterschied zwischen O(1), O(n), O(nÂ²), O(n log n), O(log n)
- [ ] Ich kann die KomplexitÃ¤t eines gegebenen Codes analysieren
- [ ] Ich weiÃŸ, wann Konstanten und niedrigere Terme zu ignorieren sind

### Arrays & Operationen
- [ ] Ich kann erklÃ¤ren, warum Array-Zugriff O(1) und Insertion in der Mitte O(n) ist
- [ ] Ich kann Array-Methoden (append, insert, remove, pop) und deren KomplexitÃ¤t nennen
- [ ] Ich kann einfache Array-Probleme wie Two-Sum lÃ¶sen
- [ ] Ich verstehe Slice-Operationen und deren KomplexitÃ¤t

### Sortieralgorithmen
- [ ] Ich kann jeden Sortieralgorithmus implementieren und erklÃ¤ren
- [ ] Ich weiÃŸ, welche Algorithmen stabil und welche in-place sind
- [ ] Ich kann fÃ¼r ein gegebenes Szenario den passenden Algorithmus wÃ¤hlen
- [ ] Ich kann erklÃ¤ren, wann Bubble/Selection/Insertion vs. Quick/Merge zu verwenden sind
- [ ] Ich verstehe, dass Counting Sort und Radix Sort nicht vergleichend sind
- [ ] Ich weiÃŸ, dass Python's sorted() Timsort verwendet (Merge + Insertion)

### Suchalgorithmen
- [ ] Ich kann Linear Search implementieren und weiÃŸ, dass O(n) ist
- [ ] Ich kann Binary Search implementieren und Boundary-Fehler vermeiden
- [ ] Ich weiÃŸ, dass Binary Search O(log n) ist und ein Sortier-Voraussetzung braucht
- [ ] Ich kann Varianten implementieren (first/last occurrence, insert position)
- [ ] Ich weiÃŸ, wann Linear vs. Binary Search zu verwenden ist

### Datenstrukturen
- [ ] Ich kann Stack mit push/pop/peek implementieren und verstehe LIFO
- [ ] Ich kann Queue mit enqueue/dequeue implementieren und verstehe FIFO
- [ ] Ich weiÃŸ, dass `collections.deque` fÃ¼r O(1) Queue-Operationen nÃ¶tig ist
- [ ] Ich kann Stack-Anwendungen nennen (Undo, Parentheses, DFS)
- [ ] Ich kann Queue-Anwendungen nennen (BFS, Task-Scheduling, Printer)
- [ ] Ich kenne Stack und Queue Best-Practices

---

## ğŸ›¤ï¸ Empfohlener Lernpfad

### Phase 1: Grundlagen verstehen (Woche 1)
1. **Why Learn DSA** - Motivation und Kontext
2. **Big O Notation** - Essentiell vor allem anderen
3. **Arrays** - VerstÃ¤ndnis von Speicher und Operationen
4. â†’ Nach dieser Phase: KÃ¶nnen Sie die Performance verschiedener Operationen analysieren

### Phase 2: Einfache Sortieralgorithmen (Woche 2)
5. **Bubble Sort** - Am einfachsten zu verstehen
6. **Selection Sort** - Ã„hnliches Konzept, weniger Swaps
7. **Insertion Sort** - Adaptive, besser als die ersten zwei
8. â†’ Nach dieser Phase: Verstehen Sie die O(nÂ²) Sortierung und ihre Trade-offs

### Phase 3: Fortgeschrittene Sortierung (Woche 3)
9. **Quick Sort** - Divide & Conquer, praktisch am schnellsten
10. **Merge Sort** - Garantiert O(n log n), stabil
11. â†’ Nach dieser Phase: KÃ¶nnen Sie komplex sortierte Probleme lÃ¶sen

### Phase 4: Spezielle Sortierung (Woche 3-4)
12. **Counting Sort** - Nicht-vergleichend fÃ¼r bekannte Bereiche
13. **Radix Sort** - Linear fÃ¼r Ziffern
14. â†’ Nach dieser Phase: Wissen Sie, wann spezialisierte Algorithmen besser sind

### Phase 5: Suche & erste Datenstrukturen (Woche 4)
15. **Linear Search** - Einfach, unentbehrlich fÃ¼r Unsortiertes
16. **Binary Search** - Schnell, erfordert Sortierung
17. **Stacks** - Erste echte Datenstruktur (LIFO)
18. **Queues** - Zweite Datenstruktur (FIFO)
19. â†’ Nach dieser Phase: Master of DSA Linear! Bereit fÃ¼r Trees/Graphs

### Empfohlene Praxis-Reihenfolge
- **Nach Phase 2**: LeetCode Easy: Bubble/Selection Sort Probleme
- **Nach Phase 3**: LeetCode Medium: Quick/Merge Sort Varianten
- **Nach Phase 4**: LeetCode Medium: Sorting + Edge Cases
- **Nach Phase 5**: LeetCode Easy: Binary Search, Stack, Queue
- **Parallel**: Implementiere jeden Algorithmus mindestens 5 mal selbst

---

## ğŸ’¡ Wichtige Lernprinzipien

### 1. Visualisieren ist KÃ¶nig
- Zeichne die Algorithmen auf Papier
- Nutze die ASCII-Diagramme in den Kursen
- Verwende Online-Visualizer fÃ¼r VerstÃ¤ndnis

### 2. Implementiere selbst
- Code von Hand, nicht nur lesen
- Versuche ohne Spickzettel zu schreiben
- Teste mit verschiedenen Eingaben (sorted, reverse, duplicates)

### 3. Verstehe Trade-offs
- Space vs. Time KomplexitÃ¤t
- StabilitÃ¤t (wichtig fÃ¼r spÃ¤tere Probleme)
- In-Place vs. extra Memory

### 4. Teste Boundary Cases
- Leere Arrays
- Single Element
- Duplicates
- Bereits sortierte/reverse sortierte Arrays
- Arrays mit 2-3 Elementen

### 5. Wiederhole, wiederhole, wiederhole
- Mindestens 3-5x pro Algorithmus
- Nach 1 Woche nochmal wiederholen
- Nach 1 Monat nochmal intensiv Ã¼ben

---

## ğŸš€ NÃ¤chste Schritte nach diesem Kurs

1. **Intermediate: Non-Linear DSA**
   - Trees (Binary, BST, AVL)
   - Graphs (DFS, BFS, Dijkstra)
   - Hash Tables & Heaps

2. **Advanced Topics**
   - Dynamic Programming
   - Greedy Algorithms
   - Backtracking
   - System Design

3. **Interview Preparation**
   - LeetCode (150+ Medium problems)
   - HackerRank
   - GeeksforGeeks
   - "Cracking the Coding Interview"

4. **Real Projects**
   - Implementiere einen Mini-Sorter in Python
   - Baue einen Task Scheduler mit Queue
   - Schreib einen einfachen Text Editor mit Undo (Stack)
   - Implementiere einen Cache mit LRU Policy

---

## ğŸ“š Zusammengefasste KomplexitÃ¤tstafel

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              QUICK REFERENCE CHEAT SHEET                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                            â•‘
â•‘  Bekommst du ein Feld von n Elementen:                     â•‘
â•‘  â”œâ”€ Sortiert?                                              â•‘
â•‘  â”‚  â””â”€ JA â†’ Binary Search O(log n)                         â•‘
â•‘  â”‚  â””â”€ NEIN â†’ Linear Search O(n)                           â•‘
â•‘  â”‚                                                         â•‘
â•‘  â”œâ”€ Muss Sortierung durchfÃ¼hren?                           â•‘
â•‘  â”‚  â”œâ”€ Kleine Array (< 50) â†’ Insertion Sort O(nÂ²)          â•‘
â•‘  â”‚  â”œâ”€ GroÃŸe Array, beliebige Daten â†’ Quick Sort           â•‘
â•‘  â”‚  â”œâ”€ Brauche garantiert O(n log n) â†’ Merge Sort          â•‘
â•‘  â”‚  â”œâ”€ Integers mit bekanntem Bereich â†’ Counting Sort      â•‘
â•‘  â”‚  â””â”€ Viele Ziffern/Stellen â†’ Radix Sort                  â•‘
â•‘  â”‚                                                         â•‘
â•‘  â”œâ”€ Datenstruktur gefragt?                                 â•‘
â•‘  â”‚  â”œâ”€ LIFO (Last rein, first raus) â†’ Stack                â•‘
â•‘  â”‚  â”œâ”€ FIFO (First rein, first raus) â†’ Queue               â•‘
â•‘  â”‚  â”œâ”€ Brauche Minimum schnell â†’ Min Stack/Heap            â•‘
â•‘  â”‚  â””â”€ Brauchte PrioritÃ¤t â†’ Priority Queue                 â•‘
â•‘  â”‚                                                         â•‘
â•‘  â””â”€ KomplexitÃ¤t analysieren?                               â•‘
â•‘     â†’ ZÃ¤hle Loops: n Loops = O(n), nÂ² = O(nÂ²)              â•‘
â•‘     â†’ Halbe GrÃ¶ÃŸe: O(log n)                                â•‘
â•‘     â†’ Mult mit kombinieren: O(n Ã— log n) etc.              â•‘
â•‘                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ“ Final Wisdom

> Verstehe nicht nur Algorithmen, sondern warum sie funktionieren.
> Implementiere nicht nur Code, sondern verstehe Trade-offs.
> Lerne nicht nur fÃ¼r Interviews, sondern um besserer Programmierer zu sein.

**Die beste Zeit zum Lernen von DSA ist jetzt. Die zweitbeste Zeit ist morgen. Also beginne heute!** ğŸ’ª

---

*Alle 14 Topics gelÃ¶st. Bereit fÃ¼r Trees, Graphs und Dynamic Programming? Los geht's!*

[[00_Index|â† ZurÃ¼ck zum Index]]

